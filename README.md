### Hi there ðŸ‘‹, my name is Nickolas!
#### As a Junior Data Engineer, I'm skilled in building data pipelines (Airflow, dbt, Soda) that ensure data quality and empower data exploration (Metabase, Looker, Grafana).
#### Leveraging my proficiency in Python, SQL, Docker, and Git, I actively design, implement, and maintain robust ETL workflows across cloud platforms.

Here's a breakdown of my cloud skills:

**AWS:** I effectively manage data ingestion using Kinesis Firehose for real-time streaming and Lambda functions for serverless processing. For storage and management, I utilize S3 and Glue, which also offers ETL workflow orchestration. Finally, I can query transformed data with Athena and create interactive visualizations with QuickSight.

**GCP:** My experience extends to BigQuery and Looker, allowing me to work with scalable data storage, analytics, and data visualization within the GCP ecosystem.

I'm a continuous learner, constantly seeking opportunities to expand my skillset and contribute to the field of data engineering.

And now a glimpse of what I've accomplished:

**Serverless AWS Data Engineering Project:** Built a serverless data pipeline using AWS services to ingest, transform, and visualize real-time weather data. This project involved leveraging Lambda functions, Kinesis Firehose for streaming data, Glue ETL Workflows for data transformation, Athena for querying transformed data, and Grafana Cloud for data visualization.

**GitHub Repository:** [aws_severless_project](https://github.com/NickolasB98/aws_severless_project)  

**Data Analytics AWS QuickSight Project:** Utilized S3 and AWS QuickSight to analyze historical data on Netflix movies and TV shows. I leveraged a JSON manifest to configure QuickSight and perform insightful data exploration.

**LinkedIn Link:** [My LinkedIn Post](https://www.linkedin.com/feed/update/urn:li:activity:7199125001491361792/)  

**DBT, GCP BigQuery, Looker Data Engineering Project**:
In this project, I explored DBT (Data Build Tool) and BigQuery to construct a data transformation pipeline. DBT's SQL-based approach offered a familiar language for data manipulation, streamlining the process.
I wrote and tested SQL-based transformations (models) within DBT. These models executed directly in BigQuery, transforming raw data into a usable format.
The transformed data resided in BigQuery, a powerful and scalable data warehouse. This ensured efficient storage and retrieval of large datasets.
Finally, I connected Looker Studio to the BigQuery instance. This enabled interactive data visualization through drag-and-drop actions, allowing me to explore the transformed data.

**GitHub Repository:** [dbt_bigquery_de_project](https://github.com/NickolasB98/dbt_bigquery_de_project) 

**Data Pipeline for Automated Report Quality & Visualization Project (Airflow, dbt, BigQuery, Metabase)**

This project automates report quality checks and data visualizations using a powerful tech stack. Airflow orchestrates the execution of data quality checks written in YAML files. These checks are powered by Soda, a framework specifically designed for data validation. dbt seamlessly integrates with Airflow using Cosmos/Astro, an extension that allows automatic execution of dbt models within Airflow workflows. This streamlines data transformation for analysis in BigQuery, the project's data warehouse. For data management, the pipeline leverages the Astro SDK and its Load File Operator. This operator simplifies loading data into BigQuery, ensuring efficient data storage. Python virtual environments and the Python Operator within Airflow provide flexibility for running custom Python code within the pipeline. This allows for handling unique situations and adding custom logic.

This approach streamlines the process, ensures data accuracy through Soda checks, and empowers clear data insights with dbt and Metabase visualizations. 

**GitHub Repository:** [airflow-bigquery-dbt-retail-data-pipeline](https://github.com/NickolasB98/airflow-bigquery-dbt-retail-data-pipeline) 

**MSc Thesis on Predictive Fairness in Healthcare:** My Master's thesis explored the potential for bias in machine learning models used for patient readmission prediction in healthcare. Through this research, I developed a framework for identifying and mitigating bias in these models, emphasizing the importance of data engineering techniques and explainable AI tools in achieving fair and accurate predictions. The focus of this project is on utilizing xAI techniques and Fair AI Libraries for Machine Learning Bias Management across its life cycle.

**GitHub Repository:** [TOM_Thesis](https://github.com/NickolasB98/TOM_Thesis ) 

**Skills:** 
Python | ETL | SQL | AWS (Kinesis Firehose, Lambda, S3, Athena, EventBridge, Glue ETL Workflow, Glue Crawler, QuickSight) | GCP (BigQuery, GSB, Looker) | dbt | Git | Machine Learning | Linux CMD

- ðŸ”­ Iâ€™m currently working on hands-on Cloud projects to gain experience in cloud engineering. 
- ðŸŒ± Iâ€™m currently learning PySpark and SparkSQL on real-life practice examples. In the meantime, I am getting more experience in Docker, considering it vital to master for my career path. 
- ðŸ’¬ Open to working on projects that involve building and deploying machine learning pipelines on the cloud. My skills in both cloud and ML can be a valuable asset. 
- ðŸ“« How to reach me: nikosdbiniaris@yahoo.com 


[<img src='https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/github.svg' alt='github' height='40'>](https://github.com/NickolasB98)  [<img src='https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/linkedin.svg' alt='linkedin' height='40'>](https://www.linkedin.com/in/nikolaos-biniaris-589517187/)  

[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=NickolasB98)](https://github.com/anuraghazra/github-readme-stats)

